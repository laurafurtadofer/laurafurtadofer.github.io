[
  {
    "objectID": "viz1.html",
    "href": "viz1.html",
    "title": "Hollywood Age Gaps",
    "section": "",
    "text": "Hollywood Age Gaps Over Time\n\n\n\n\nThis plot shows that couple age gaps have remained pretty consistent over time and that the data was skewed towards more recent movies. It also shows that there are many more non-same gender couples than same gender couples in Hollywood movies but that the same gender couples are equally spread out along the age gap axis. Same gender couples only appeared in this Hollywood data set after the year 2000.\nCitations:\nThis data comes from Hollywood Age Gap via Data Is Plural.\nData Science Learning Community (2024). Tidy Tuesday: A weekly social data project. https://tidytues.day\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2023/2023-02-14"
  },
  {
    "objectID": "viz2.html",
    "href": "viz2.html",
    "title": "Valentines Gift Habits",
    "section": "",
    "text": "Valentines Gifts by Age Group\n\n\n\n\nThis plot shows that people’s shopping habits on valentines day stay pretty stable with age. The few differences are in the purchase of jewelry and greeting cards. The proportion of jewelry purchased compared to other items declines after people turn 44 and the proportion of greeting cards purchased picks up at age 35+.\nCitations:\nThis data comes from The National Retail Federation in the United States’ Valentine’s Day Data Center, specifically the Valentine’s Day survey data.\nData Science Learning Community (2024). Tidy Tuesday: A weekly social data project. https://tidytues.day\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2024/2024-02-13"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laura Furtado Fernandes",
    "section": "",
    "text": "Hi there! My name is Laura. I’m currently a Senior at Pomona College taking a class to learn data science skills (Foundations of Data Science in R)! I’m a Psychological Science Major and work as a research assistant at the MIC Lab and the PPPR Lab. I have three dogs and love going to the beach!"
  },
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Project 5",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(RMariaDB)\nlibrary(DBI)\n\n\n\n\nShow the code\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nThe Stanford Open Policing Project compiled data from police stops from 42 different states across the United States. In this project, I analyze the racial make up of police stops in three major California cities—Los Angeles, San Diego, and San Francisco—to explore differences in stop patterns across locations and stop types. I will use SQL to access this data and wrangle it to examine my variables of interest: the race of the person stopped by police and the type of stop. I will limit my analyses to the year 2015.\n\n\nShow the code\nSELECT * FROM (\n  SELECT subject_race, type,   \n   SUM(1) AS num_stops,\n   'los angeles' AS city\n  FROM ca_los_angeles_2020_04_01\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n\n  UNION ALL\n\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n    'san diego' AS city\n  FROM ca_san_diego_2020_04_01\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n\n  UNION ALL\n\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n   'san francisco' AS city\n  FROM ca_san_francisco_2020_04_01\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n) AS combined\nORDER BY num_stops DESC;\n\n\n\nDisplaying records 1 - 10\n\n\nsubject_race\ntype\nnum_stops\ncity\n\n\n\n\nhispanic\nvehicular\n164909\nlos angeles\n\n\nwhite\nvehicular\n87406\nlos angeles\n\n\nblack\nvehicular\n86184\nlos angeles\n\n\nhispanic\npedestrian\n60898\nlos angeles\n\n\nwhite\nvehicular\n48758\nsan diego\n\n\nblack\npedestrian\n42330\nlos angeles\n\n\nhispanic\nvehicular\n33609\nsan diego\n\n\nwhite\nvehicular\n29867\nsan francisco\n\n\nother\nvehicular\n29488\nlos angeles\n\n\nwhite\npedestrian\n24944\nlos angeles\n\n\n\n\n\nThe table above displays the number and type of police stops by race across three California cities, ordered in descending fashion by total number of stops. The plot below visualizes these results. Los Angeles recorded the highest number of stops overall, with Hispanic individuals being stopped most frequently in both vehicular and pedestrian contexts. San Diego is a distant second in terms of overall stops, with San Francisco coming last in this comparison. In San Diego and San Francisco, white drivers are stopped most often, however, these results must be taken in consideration of the racial make up of the three cities.\nAccording to the U.S. Census Bureau, Los Angeles has a Hispanic majority, with approximately 47% of its population identifying as Hispanic. In contrast, San Diego’s population is majority White, with 50% identifying as White. Similarly, in San Francisco, White individuals also make up the largest racial group, comprising about 50% of the population.\nSan Francisco and San Diego lack data on pedestrian stops which limits this comparison.\n\n\nShow the code\ndf &lt;- dbGetQuery(con_traffic, \"\n  SELECT subject_race, type,   \n  SUM(1) AS num_stops,\n  'los angeles' AS city\nFROM ca_los_angeles_2020_04_01\nWHERE type IS NOT NULL\n  AND date BETWEEN '2015-01-01' AND '2015-12-31'\nGROUP BY  subject_race, type\n\nUNION ALL\n\nSELECT subject_race, type,   \n  SUM(1) AS num_stops,\n  'san diego' AS city\nFROM ca_san_diego_2020_04_01\nWHERE type IS NOT NULL\n  AND date BETWEEN '2015-01-01' AND '2015-12-31'\nGROUP BY  subject_race, type\n\nUNION ALL\n\nSELECT subject_race, type,   \n  SUM(1) AS num_stops,\n  'san francisco' AS city\nFROM ca_san_francisco_2020_04_01\nWHERE type IS NOT NULL\n  AND date BETWEEN '2015-01-01' AND '2015-12-31'\nGROUP BY  subject_race, type\n\")\n\nggplot(df, aes(x = subject_race, y = num_stops, fill = type)) + \n  geom_col(position = \"dodge\") + \n  labs(\n    title = \"Number of Stops by Race and Stop Type in Los Angeles, \\nSan Diego and San Francisco in 2015\",\n    x = \"Subject Race\",\n    y = \"Number of Stops\",\n    fill = \"Stop Type\"\n  ) +\n  theme_minimal() +\n  facet_wrap( . ~ city) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nComparing within California is good to get a sense of within state differences in traffic stop patterns, however, these comparisons are not without limitations. For instance, Los Angeles is much more car reliant than San Francisco and also much more populous. San Diego might be more car-centric than San Francisco but Los Angeles experiences much higher traffic and has more extensive freeways than San Diego. Therefore, I decided to compare Los Angeles, California, to another highly car-centered city: Houston, Texas.\n\n\nShow the code\nSELECT * FROM (\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n    'los angeles' AS city\n  FROM ca_los_angeles_2020_04_01\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n\n  UNION ALL\n\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n   'houston' AS city\n  FROM tx_houston_2023_01_26\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n) AS combined\nORDER BY num_stops DESC;\n\n\n\nDisplaying records 1 - 10\n\n\nsubject_race\ntype\nnum_stops\ncity\n\n\n\n\nwhite\nvehicular\n169470\nhouston\n\n\nhispanic\nvehicular\n164909\nlos angeles\n\n\nblack\nvehicular\n96645\nhouston\n\n\nwhite\nvehicular\n87406\nlos angeles\n\n\nblack\nvehicular\n86184\nlos angeles\n\n\nhispanic\npedestrian\n60898\nlos angeles\n\n\nNA\nvehicular\n46001\nhouston\n\n\nblack\npedestrian\n42330\nlos angeles\n\n\nother\nvehicular\n29488\nlos angeles\n\n\nwhite\npedestrian\n24944\nlos angeles\n\n\n\n\n\nThe table above displays the number and type of police stops by race in Los Angeles, CA, and Houston, TX, ordered in descending order by total stops. The plot below visualizes this data. Compared to other California cities, Houston and Los Angeles show more similar overall stop volumes. In Houston, White individuals are the most frequently stopped demographic, followed by Black individuals. In contrast, Los Angeles shows comparable numbers of vehicular stops for Black and White individuals, but White individuals are stopped less often in pedestrian encounters.\nHouston is missing data on pedestrian stops and on stops of Hispanic individuals which makes again limits comparisons.\n\n\nShow the code\ndf &lt;- dbGetQuery(con_traffic, \"\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n    'los angeles' AS city\n  FROM ca_los_angeles_2020_04_01\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n\n  UNION ALL\n\n  SELECT subject_race, type,   \n    SUM(1) AS num_stops,\n   'houston' AS city\n  FROM tx_houston_2023_01_26\n  WHERE type IS NOT NULL\n    AND date BETWEEN '2015-01-01' AND '2015-12-31'\n  GROUP BY  subject_race, type\n\")\n\nggplot(df, aes(x = subject_race, y = num_stops, fill = type)) + \n  geom_col(position = \"dodge\") + \n  labs(\n    title = \"Number of Stops by Race and Stop Type in Los Angeles and Houston in 2015\",\n    x = \"Subject Race\",\n    y = \"Number of Stops\",\n    fill = \"Stop Type\"\n  ) +\n  theme_minimal() +\n  facet_wrap( . ~ city) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nIn this project, I used SQL to analyze police stop data from the Stanford Open Policing Project, focusing on racial patterns and stop types in three major California cities—Los Angeles, San Diego, and San Francisco—as well as a cross-state comparison with Houston, Texas. Within California, Los Angeles showed the highest number of stops, but the distribution of stops by race varied between cities. While comparing Los Angeles and Houston, I ran into an issue of missing data on the ethnicity (whether person stopped was of Hispanic origin) of the person stopped which limited comparisons with Los Angeles, which has a large hispanic population. I did see that Houston and Los Angeles have similar traffic stop counts, with makes sense given the car-centered culture of both cities.\nReferences:\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10.\nBureau, U. C. (n.d.). Census.gov | U.S. Census Bureau Homepage. Census.Gov. Retrieved April 29, 2025, from https://www.census.gov/en.html"
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "Project 4",
    "section": "",
    "text": "Facebook Ethical Dilemma\nIn 2014, a paper titled ‘Experimental Evidence of Massive-Scale Emotional Contagion through Social Networks’ was published in Proceedings of the National Academy of Sciences of the United States of America (Kramer et al., 2014). This paper details the results from a large-scale experiment conducted on 689,003 English-speaking Facebook users to examine how the valence (positive or negative) of their News Feed content influenced their behavior on Facebook over a period of 1 week. Specifically, they measured whether people who saw differently valenced News Feeds used different percentages of positive vs negative words in their posts. This research, however, became highly controversial because it seemingly ignored pillars of academic investigation and data science, like informed consent, ethical data collection, improving lives, data transparency and availability, and generalizability.\nInformed Consent Violations\nFirstly, in order to do this research and observe emotion contagion, the researchers manipulated users’ news feeds and, in essence, experimented on them without their informed consent. Participants were recruited and randomly assigned to conditions without being informed of participation in the study (Kramer et al. 2014). There are obvious ethical issues with this, as manipulating participants without their consent goes against the Belmont Report’s guidelines for research on human participants (Protections, 2010). Some argued that this sort of research is commonplace in industry (Park, 2014; Boesel, 2014) and that it only became unethical when it was published and fell short of the moral standards expected of academics (Park, 2014). Especially since it was done in collaboration with Cornell University: the Facebook researcher, Adam Kramer, partnered with two Cornell University investigators, Jamie Guillory and Jeffrey Hancock, in this project. The Cornell Institutional Review Board deemed the study exempt from their oversight because the data was being collected by Facebook, and some argue that it was a mistake (Boesel, 2014). This study violated the informed consent and ethical data collection principles of data science research.\nFailure to Improve Lives\nThe Facebook emotional contagion study also violated the data science principle that data should be used to improve the lives of individuals and communities. One could argue that this research is valuable and that the findings are beneficial to humanity because understanding emotional contagion is important and that this was the only way to study emotional contagion. However, that is not entirely true. Emotion contagion had been studied in more naturalistic ways years before Kramer et al. (2014) did it. Fowler & Christakis (2008) studied emotion contagion in social networks over a period of 20 years, 4739 participants consented to participate in a study; they found that there are clusters of happy and unhappy people in social networks and that happiness spread through the network, if a friend who lives within a mile becomes happy, it increases the probability that a person is happy by 25%. You could then argue that this effect is understudied in social media and that this was the only way to accurately do that, and that would also not be entirely true. One year after Kramer et al. (2014) published their study, and in response to the controversy, Ferrara and Yang (2015) investigated emotional contagion in social media by observing people on Twitter and measuring the valence of the content they had been exposed to without manipulating it. Therefore, the Facebook study not only introduced ethical harm (via emotional manipulation without consent) but also failed to generate new insights that justified those harms.\nLack of Transparency\nAdditionally, if this research had truly been revolutionary and overwhelmingly beneficial to others, then it stands to reason that the data collected in this study should be made publicly available and transparent which was not the case (Kramer et al., 2014). Instead, interested parties could reach out to Kramer et al. to request access to the data. This limits the work’s reproducibility and extension of the findings, violating data science principles.\nGeneralizability and Bias\nFurthermore, this research was conducted solely with English-speaking individuals who use Facebook, which raises concerns about cross-culture generalizability (Kramer et al., 2014). Then, can we claim that the findings are generalized to all of humanity? Or just to English-speaking, rich, industrialized populations? In this case, this research and findings are also perpetuating issues in the field of behavioral science, like the over-representation of WEIRD populations (Apa.Org, 2025). Given the access that Facebook had, they should and could have made this research more inclusive.\nReferences:\nAre your findings “WEIRD”? (n.d.). Https://Www.Apa.Org. Retrieved April 16, 2025, from https://www.apa.org/monitor/2010/05/weird\nBoesel, W. E. (2014, July 3). Facebook’s Controversial Experiment: Big Tech Is the New Big Pharma. TIME. https://time.com/2951726/facebook-emotion-contagion-experiment/\nFowler, J. H., & Christakis, N. A. (2008). Dynamic spread of happiness in a large social network: Longitudinal analysis over 20 years in the Framingham Heart Study. BMJ (Clinical Research Ed.), 337, a2338. https://doi.org/10.1136/bmj.a2338\nFerrara, E., & Yang, Z. (2015). Measuring Emotional Contagion in Social Media. PLOS ONE, 10(11), e0142390. https://doi.org/10.1371/journal.pone.0142390\nKramer, A. D., Guillory, J. E., and Hancock, J. T. (2014), Experimental Evidence of Massive-Scale Emotional Contagion through Social Networks, Proceedings of the National Academy of Sciences of the United States of America, 111, 8788–8790\nPark, A. (2014, June 30). Calm Down: Facebook Isn’t Really Manipulating Your Emotions. TIME. https://time.com/2941513/calm-down-facebook-isnt-manipulating-your-emotions/\nProtections (OHRP), O. for H. R. (2010, January 28). The Belmont Report [Page]. https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/index.html"
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Project 2",
    "section": "",
    "text": "Show the code\nhowyoudoin &lt;- friends %&gt;% \n  filter(speaker == \"Joey Tribbiani\") %&gt;% \n  filter(str_detect(text, \"(?i)How you doin'\\\\?\")) %&gt;% \n  group_by(season) %&gt;% \n  summarise(howyoudoin_count = n()) %&gt;% \n  mutate(season = as.character(season)) \n\nhowyoudoinmerge &lt;- data.frame(\n  season = c(\"1\", \"2\", \"3\", \"10\"), \n  howyoudoin_count = c(0, 0, 0, 0)\n)\n\nhowyoudoin &lt;- bind_rows(howyoudoin, howyoudoinmerge) %&gt;% \n  mutate(season = factor(season, levels = sort(unique(as.numeric(season)))))\n\n\nggplot(howyoudoin, \n       aes(x = season, y = howyoudoin_count)) + \n  geom_col(aes(fill = season, colour = season)) + \n  labs(x = \"Season\", \n       y = \"Number of times Joey says 'how you doin'\", \n       title = \"How each season of Friends is doin'\") + \n  theme_minimal() + \n  theme(legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nThis is a bar plot displaying how often Joey says “How you doin’?” per season of Friends. Joey first says his iconic catchphrase in season 4! It peaks during season 6 and by season 9 Joey barely says it anymore. This could reflect Joey’s character development as less of a ladies man or, that the writers grew tired of this joke.\n\n\nShow the code\nsmelly_cat &lt;- friends %&gt;% \n  mutate(smelly_cats = str_count(text, \"(?i)\\\\bsmelly cat\\\\b\")) %&gt;% \n  group_by(episode, season) %&gt;%\n  summarise(total_smelly_cats = sum(smelly_cats)) %&gt;% \n  ungroup()\n\nutterances_by_char &lt;- friends %&gt;% \n  group_by(season, episode, speaker) %&gt;%\n  summarise(total_utterances = n()) %&gt;% \n  ungroup() %&gt;% \n  filter(speaker == \"Chandler Bing\" | speaker == \"Monica Geller\" | speaker == \"Joey Tribbiani\" | speaker == \"Phoebe Buffay\" | speaker == \"Ross Geller\"| speaker == \"Rachel Green\")\n  \nsmelly_cats_char &lt;- left_join(utterances_by_char, smelly_cat)\n  \nggplot(smelly_cats_char, aes(x = total_utterances, y = total_smelly_cats)) + \n  geom_jitter(aes(colour = speaker, alpha = ifelse(total_smelly_cats == 0, 0.25, 1))) + \n  scale_alpha_identity() +  \n  labs(\n    title = \"Smelly Cat's Relationship to Character Dialogue\",\n    x = \"Total Utterances per Episode\",\n    y = \"Total 'Smelly Cat' Mentions per Episode\",\n    colour = \"Speaker\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis is a scatter plot displaying the total number of utterances per character (main 5 friends) in every episode of friends vs the total mentions of ‘Smelly Cat’. Surprisingly, on episodes with more ‘Smelly Cat’ mentions, Phoebe does not speak more often than the other friends.\n\n\nShow the code\nspeaking_len &lt;- friends %&gt;% \n  mutate(utterance_length = str_length(text)) %&gt;% \n  mutate(season = as.character(season)) %&gt;%\n  mutate(speaker = ifelse(speaker == \"Chandler Bing\" | speaker == \"Monica Geller\" | speaker == \"Joey Tribbiani\" | speaker == \"Phoebe Buffay\" | speaker == \"Ross Geller\"| speaker == \"Rachel Green\", speaker, \"Other\")) %&gt;%\n  group_by(episode, speaker) %&gt;% \n  summarise(avg_utt_length = mean(utterance_length, na.rm = TRUE)) %&gt;% \n  ungroup() %&gt;% \n  filter(!is.na(speaker), speaker != \"Other\")\n  \n\nggplot(speaking_len, aes(x = episode, y = avg_utt_length)) + \n  scale_colour_brewer(palette=\"Set1\") + \n  geom_point(aes(colour = speaker)) +  \n  geom_smooth(aes(colour = speaker), se = FALSE) +\n  labs(\n    x = \"Episodes\", \n    y = \"Average Utterance Length\", \n    title = \"Change in Friends Character Utterance Length Over an Average Season\"\n  ) +\n  theme_minimal() + \n  facet_wrap(~speaker)\n\n\n\n\n\n\n\n\n\nShow the code\nspeaking_len &lt;- friends %&gt;% \n  mutate(utterance_length = str_length(text)) %&gt;% \n  mutate(speaker = ifelse(speaker == \"Chandler Bing\" | speaker == \"Monica Geller\" | speaker == \"Joey Tribbiani\" | speaker == \"Phoebe Buffay\" | speaker == \"Ross Geller\"| speaker == \"Rachel Green\", speaker, \"Other\")) %&gt;%\n  group_by(season, speaker) %&gt;% \n  summarise(avg_utt_length = mean(utterance_length, na.rm = TRUE)) %&gt;% \n  ungroup() %&gt;% \n  filter(!is.na(speaker), speaker != \"Other\")\n\nggplot(speaking_len, aes(x = season, y = avg_utt_length)) + \n  scale_colour_brewer(palette=\"Set1\") + \n  geom_point(aes(colour = speaker)) + \n  geom_smooth(aes(colour = speaker), se = FALSE) + \n  scale_x_continuous(limits = c(1, 10), breaks = seq(1, 10, by = 1)) +\n  labs(x = \"Season\", \n       y = \"Average Utterance Length\", \n       title = \"Change in Friends Character Utterance Length Over the Series\") +\n  theme_minimal() + \n  facet_wrap(~speaker)\n\n\n\n\n\n\n\n\n\nThese are scatter plots with trend-lines displaying how average utterance length changes over time for each speaker, in both the span of the average season (per episode) and over the series (per season). Over the course of an average season of Friends, the characters utterances seem to get shorter (except for Chandler and Phoebe). Most characters utterance lengths fluctuated throughout the seasons. Notably, in season 1, Monica starts out with the shortest utterences and she slowly starts speaking longer utterances from season five onwards.\n\n\nShow the code\njanice &lt;- friends %&gt;%\n  mutate(Janices = str_count(text, \"(?&lt;=Janice)\\\\b\")) %&gt;%\n  filter(speaker == \"Chandler Bing\" | speaker == \"Monica Geller\" | speaker == \"Joey Tribbiani\" | speaker == \"Phoebe Buffay\" | speaker == \"Ross Geller\"| speaker == \"Rachel Green\" | speaker == \"Janice Litman Goralnik\" ) %&gt;% \n  group_by(speaker) %&gt;% \n  summarise(total_janices = sum(Janices))\n\n\nggplot(janice, \n       aes(x = speaker, y = total_janices)) + \n  geom_col(aes(fill = speaker)) + \n  scale_fill_brewer(palette=\"GnBu\") + \n  labs(x = \"Speaker\", \n       y = \"Times Referenced Janice\", \n       title = \"Who is most burdened by Janice?\") + \n  theme_minimal() + \n  theme(legend.position=\"none\") + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThis is a bar plot reflecting how often the characters in Friends refer to Janice. Chandler refers to Janice the most out of all his friends, this makes sense since he dates her throughout the series. Rachel is the character least burdened by Janice which must surely result in mental or ear health benefits.\n\n\nShow the code\nfirst &lt;- friends %&gt;% \n  filter(speaker != \"Scene Directions\") %&gt;% \n  group_by(season, episode) %&gt;% \n  slice_min(order_by = utterance, n = 1) %&gt;% \n  ungroup() %&gt;%\n  filter(scene == 1) %&gt;%\n  mutate(speaker = ifelse(speaker == \"Chandler Bing\" | speaker == \"Monica Geller\" | speaker == \"Joey Tribbiani\" | speaker == \"Phoebe Buffay\" | speaker == \"Ross Geller\"| speaker == \"Rachel Green\", speaker, \"Other\")) %&gt;%\n  group_by(speaker) %&gt;% \n  summarise(firstspeaker_count = n())\n\nggplot(first, \n       aes(x = speaker, y = firstspeaker_count)) + \n  geom_col(aes(fill = speaker)) + \n  scale_fill_brewer(palette=\"RdPu\") + \n  labs(x = \"Speaker\", \n       y = \"Times first to speak in an episode\", \n       title = \"Whose voice do you hear first in a Friends episode?\") + \n  theme_minimal() + \n  theme(legend.position=\"none\") \n\n\n\n\n\n\n\n\n\nThis is a bar plot showing how often the first line in an episode is spoken by each friend or generic other character. Joey is most often the first to speak, followed by Chandler. This probably reflects the writers desire to start on a comic relief moment and Joey is the silliest character.\nCitations:\nThis data comes from emilhvitfeldt.github.io/friends/ + Friends [TV series]. National Broadcasting Company."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Project 3",
    "section": "",
    "text": "Athletes tend to perform better at home, and this well-known phenomenon is called “home advantage”. It happens due to a combination of fan support, familiarity with the venue, no travel stress, etc. Clube de Regatas do Flamengo (better known as Flamengo) is a fascinating case study in this context. With an estimated 40 to 50 million supporters spread across the country, Flamengo often draws large crowds regardless of location — even in away matches. In this project, I aim to investigate whether the traditional “home advantage” also applies to Flamengo or if their massive nationwide fanbase neutralizes the traditional home-field advantage. In other words: Does Flamengo play “at home” wherever they go? Or does playing in the iconic Maracanã — the most famous stadium in the world — still provide a meaningful edge? I will be measuring performance by comparing the number of goals scored by Flamengo at home vs. away.\n\n\nShow the code\nflamengo_games %&gt;%\n   mutate(\n      is_home = ifelse(home == \"Flamengo\", TRUE, FALSE),\n      goals_for = ifelse(is_home, home_goal, away_goal)\n    )  %&gt;%\n  group_by(is_home) %&gt;% \n  summarize(mean_goals = mean(goals_for)) %&gt;% \n  ggplot(aes(x = is_home, y = mean_goals, fill = is_home)) +\n  geom_col(width = 0.6) +\n  scale_fill_brewer(palette = \"PuRd\") + \n  scale_x_discrete(labels = c(\"Away\", \"Home\")) +\n  labs(\n    title = \"Flamengo's Average Goals Scored: Home vs. Away\",\n    x = \"Game Location\",\n    y = \"Average Goals Scored\", \n    fill = \"Playing at Home?\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis plot highlights the difference between Flamengo’s average goals scored at home vs away, Flamengo scores on average 1.75 goals in home matches, while scoring around 1.34 goals in away games. It is a difference of less than one goal.\n\n\nShow the code\nperm_data &lt;- function(rep, team){\n  games &lt;- br_soccer %&gt;%\n    filter(home == team | away == team) %&gt;%\n    mutate(\n      is_home = ifelse(home == team, TRUE, FALSE),\n      goals_for = ifelse(is_home, home_goal, away_goal)\n    ) %&gt;%\n    select(is_home, goals_for)\n\n  obs_diff &lt;- games %&gt;%\n    group_by(is_home) %&gt;%\n    summarize(mean_goals = mean(goals_for)) %&gt;%\n    summarize(diff = mean_goals[is_home == TRUE] - mean_goals[is_home == FALSE]) %&gt;%\n    pull(diff)\n\n  permuted &lt;- games %&gt;%\n    mutate(is_home_perm = sample(is_home))\n\n  perm_diff &lt;- permuted %&gt;%\n    group_by(is_home_perm) %&gt;%\n    summarize(mean_goals = mean(goals_for)) %&gt;%\n    summarize(diff = mean_goals[is_home_perm == TRUE] - mean_goals[is_home_perm == FALSE]) %&gt;%\n    pull(diff)\n\n  tibble(rep = rep, obs_diff = obs_diff, perm_diff = perm_diff)\n}\n\nperm_results &lt;- map(1:1000, perm_data, team = \"Flamengo\") |&gt; \n  list_rbind()\n\n\n\n\nShow the code\nggplot(perm_results, aes(x = perm_diff)) +\n  geom_histogram(bins = 30, fill = \"black\", color = \"red\") +\n  geom_vline(aes(xintercept = obs_diff), color = \"blue\", linetype = \"dashed\", linewidth = 1) +\n  labs(\n    title = \"Permutation Test: Flamengo's Home vs. Away Goal Average\",\n    x = \"Permuted Mean Difference (Home - Away)\",\n    y = \"Count\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe permutation test revealed that Flamengo does, in fact, experience a home-field advantage. As shown in the plot above, the difference in average goals scored between home and away matches (represented by the blue dashed line) is much greater than what would be expected by random chance. This provides strong evidence that Flamengo scores more goals at home than away, suggesting that playing in Maracanã may offer a meaningful boost.\nCitation:\nThis data was obtained from the Kaggle Brazilian Football Matches dataset: https://www.kaggle.com/datasets/cuecacuela/brazilian-football-matches"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is part of my Foundations of Data Science in R course at Pomona College. The analyses posted here are part of course projects!"
  }
]